{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Net_PREDICT_LABELS_A2UN91_5_HP60_nfull_lr1e-05_conv1FS60\n",
    "#MODEL_TO_LOAD = 'GRAPHBACKUPS/Net_UNBALANCED91_4_nfull_lr0.0001/model.ckpt-6'\n",
    "#MODEL_TO_LOAD = 'EPOCH_SAVED/Net_UNBALANCED91_5_nfull_lr1e-05/model.ckpt-6'\n",
    "#MODEL_TO_LOAD = 'GRAPHBACKUPS/Net_PREDICT_LABELS_A2UN91_5_HP60_nfull_lr1e-05_conv1FS60/model.ckpt-0'\n",
    "#MODEL_TO_LOAD  =\"EPOCH_SAVED/Net_PREDICT_LABELS_sedgetest4_HP30_nfull_lr0.0001_conv1FS30_mFalse/model.ckpt-0\"\n",
    "\n",
    "#MODEL_TO_LOAD = 'EPOCH_SAVED/Net_PREDICT_LABELS_A2UN91_5_HP9_nfull_lr1e-05_conv1FS9/model.ckpt-11'\n",
    "\n",
    "#These two have the hanning window on conv1\n",
    "#MODEL_TO_LOAD = \"Saved_Sessions/Net_PREDICT_LABELS_sedgetest4_HP30_nfull_lr0.0001_conv1FS30_mFalse/model.ckpt\"\n",
    "MODEL_TO_LOAD = \"Saved_Sessions/Net_PREDICT_LABELS_sedgetest5_HP30_nfull_lr1e-05_conv1FS30_mFalse/model.ckpt\"\n",
    "\n",
    "#change these to build the correct model\n",
    "\n",
    "\n",
    "TASK = \"PREDICT_LABELS\"\n",
    "#TASK = \"PREDICT_COUNTS\"\n",
    "multiple_labels = True\n",
    "Conv1_filtersize = 30\n",
    "padding = \"SAME\"\n",
    "#padding = \"VALID\"\n",
    "poolmethod =\"HPOOL\"\n",
    "#poolmethod =\"MAXPOOL\"\n",
    "conv1_times_hanning = True\n",
    "Net_or_VGG = \"Net\" \n",
    "\n",
    "#these aren't changed often.\n",
    "music_only = False \n",
    "Learning_Rate = 1e-5\n",
    "COCHLEAGRAM_LENGTH = int(342000)\n",
    "numlabels = 527\n",
    "\n",
    "limit = 1000 #does nothing here\n",
    "name = \"BBB_TEST5\" #does nothing here\n",
    "unbalanced = True #does nothing here\n",
    "folder = \"TB2\" #does nothing here\n",
    "OVERIDE_FOLDER = None#\"does nothing here\n",
    "SAVE = False #does nothing here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import sys\n",
    "import h5py\n",
    "import random\n",
    "import math\n",
    "from math import sqrt\n",
    "import argparse\n",
    "\n",
    "from IPython.core.display import HTML, display\n",
    "import scipy.signal as signal\n",
    "from scipy.io import wavfile\n",
    "\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.mlab as mlab\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from PedrosNetworkFunctions import *\n",
    "\n",
    "#####################\n",
    "#READ IN THE TESTING BATCH\n",
    "\n",
    "#set up batch with some good sounds\n",
    "\n",
    "#sounds indeces of the good samples we want to use\n",
    "#test_indeces =[4,7,10,230,233,660,1278,2079,2290,2295,5098,5104,5104,5105,6005,6025,6021,6024,6027,6009,12,10005,10015,10018,10020,10023,10035]\n",
    "\n",
    "test_indeces= [15695,10795,15732,4040,10430,13920,12071,18594,2846,2155,15131,18539,942,682,2828,12889,18257,0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17]\n",
    "\n",
    "#Cochs = h5py.File(\"/home/ribeirop/OMFOLDER/audiosetDL/balanced_stripped/balanced_train_segments_Coch.hdf5\")\n",
    "#Wavs = hdf5file=h5py.File(\"/home/ribeirop/OMFOLDER/audiosetDL/balanced_stripped/balanced_train_segments.hdf5\")\n",
    "#Wavs = hdf5file=h5py.File(\"/home/ribeirop/OMFOLDER/audiosetDL/eval_stripped/eval_segments.hdf5\")\n",
    "#Cochs = h5py.File(\"/home/ribeirop/OMFOLDER/audiosetDL/eval_stripped/eval_segments_Coch.hdf5\")\n",
    "Cochs = h5py.File(\"/home/ribeirop/OMFOLDER/audiosetDL/unbalanced_stripped/unbalanced_train_segments_Coch.hdf5\")\n",
    "Wavs = hdf5file=h5py.File(\"/om/data/public/audioset/unbalanced_stripped/unbalanced_train_segments.hdf5\")\n",
    "\n",
    "\n",
    "train_averagefile = \"/om/user/ribeirop/audiosetDL/unbalanced_stripped/unbalanced_train_segments_average.npy\"\n",
    "train_mean_coch = np.load(train_averagefile)\n",
    "\n",
    "wavSet = Wavs[\"/wav\"]\n",
    "cochSet = Cochs[\"/coch\"]\n",
    "labelSet = Cochs[\"/labels\"]\n",
    "\n",
    "coch_batch = []\n",
    "label_batch = []\n",
    "wav_batch = []\n",
    "for i in test_indeces:\n",
    "    coch_batch.append(cochSet[i])\n",
    "    label_batch.append(labelSet[i])\n",
    "    wav_batch.append(wavSet[i])\n",
    "    \n",
    "coch_batch = coch_batch*1\n",
    "label_batch = label_batch * 1\n",
    "\n",
    "indeces_list = []\n",
    "total_count = 0 #total number of labels\n",
    "for row in label_batch:\n",
    "    indeces= np.where(row==1)[0]\n",
    "    total_count = total_count + len(indeces)\n",
    "    indeces_list.append(np.pad(indeces,[0,15-len(indeces)],mode = 'constant',constant_values=-1))\n",
    "\n",
    "####################\n",
    "#READ IN NETWORK\n",
    "\n",
    "TensorBoard_Folder = './TB_Test/nettest'\n",
    "Saver_Folder = './Saved_Sessions/nettest'\n",
    "    \n",
    "nets = Gen_audiosetNet(COCHLEAGRAM_LENGTH,numlabels,train_mean_coch,Conv1_filtersize,padding, poolmethod,conv1_times_hanning=conv1_times_hanning)\n",
    "#Get the loss functions\n",
    "Cross_Entropy_Train_on_Labels(nets,numlabels,Learning_Rate,multiple_labels)\n",
    "saver = tf.train.Saver()\n",
    "print(\"done reading\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess,MODEL_TO_LOAD)\n",
    "    #now you can do things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#print all the filter maps\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess,MODEL_TO_LOAD)\n",
    "    filtermaps = sess.run(nets['grid'],feed_dict={})[0,:,:,0]\n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "    cax = ax.matshow(filtermaps, origin='lower', cmap='Greys')\n",
    "    divider = make_axes_locatable(ax)\n",
    "    cax2 = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "    fig.colorbar(cax,cax2)\n",
    "    ax.set_title(\"cov1_weights\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#print the filters (with and without hanning window)\n",
    "import matplotlib.colors as colors\n",
    "\n",
    "class MidpointNormalize(colors.Normalize):\n",
    "    def __init__(self, vmin=None, vmax=None, midpoint=None, clip=False):\n",
    "        self.midpoint = midpoint\n",
    "        colors.Normalize.__init__(self, vmin, vmax, clip)\n",
    "\n",
    "    def __call__(self, value, clip=None):\n",
    "        # I'm ignoring masked values and all kinds of edge cases to make a\n",
    "        # simple example...\n",
    "        x, y = [self.vmin, self.midpoint, self.vmax], [0, 0.5, 1]\n",
    "        return np.ma.masked_array(np.interp(value, x, y))\n",
    "\n",
    "def plot_filter_weights(nets, MODEL_TO_LOAD,style_layers, conv1_size=9, conv2_size=5, save_file=False):\n",
    "    ## Takes in the style_layers and plots the filters (and the biases) for all of the filters of the layer. \n",
    "    ## Inputs: \n",
    "    ##      checkpoint_to_load = path to the checkpoint for the tensorflow model (as a string)\n",
    "    ##      style_layers = list of the layers of the network to plot\n",
    "    ##      conv1_size = the size of the first layer filters (used for making the network)\n",
    "    ##      conv2_size = the size of the second layer filters (used for making the network)\n",
    "    ##      save_file = False if the plots shouldn't be saved, a string to the base file name if they should be saved. \n",
    "    ## Returns:\n",
    "    ##      weights = dictionary with the filter weights for each layer as an array\n",
    "    ##      biases = dictionary with the filter biases for each layer\n",
    "    \n",
    "    weights = {}\n",
    "    biases = {}\n",
    "    for layer in range(len(style_layers)):\n",
    "        weights[layer] = nets[style_layers[layer][0]].eval()\n",
    "        biases[layer] = nets[style_layers[layer][1]].eval()\n",
    "        num_filters = weights[layer].shape[-1]\n",
    "        shape_filters = weights[layer].shape[0]\n",
    "        row_filters = weights\n",
    "        num_columns = 12\n",
    "        num_rows = np.ceil(num_filters/num_columns)\n",
    "        plt.figure(figsize=(60,5*num_rows))\n",
    "        for i in range(num_filters):\n",
    "            plt.subplot(num_rows,num_columns,i+1)\n",
    "            norm = MidpointNormalize(midpoint=0)\n",
    "            plt.matshow(weights[layer][:,:,0,i], norm=norm, cmap=plt.cm.RdBu_r, fignum=False,\n",
    "                        vmin=weights[layer][:,:,0,i].min()*2, vmax=weights[layer][:,:,0,i].max()*2, interpolation='none', origin=\"lower\")\n",
    "            #plt.title(\"filter %d, bias %f\"%(i,biases[layer][i]))\n",
    "                        \n",
    "            M = float(weights[layer][:,:,0,i].max())\n",
    "            m = float(weights[layer][:,:,0,i].min())\n",
    "            #plt.title(\"filter {0}, bias {1}, Max {2}, Min {3}\".format(i,biases[layer][i],M,m))\n",
    "            plt.title(\"filter {0}, bias {1:.2f}, Max {2:.6f}, Min {3:.6f}\".format(i,biases[layer][i], M,m))\n",
    "        plt.suptitle(\"Filters and Biases for layer \" + str(layer), fontsize=50)\n",
    "        plt.show()\n",
    "        if save_file:\n",
    "            plt.savefig(save_file + layer + '_weights' + '.png')\n",
    "            plt.close()\n",
    "\n",
    "    return weights, biases\n",
    "    \n",
    "style_layers = [['conv1_Weights','conv1_bias']] #,['conv2_Weights','conv2_bias']]\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess,MODEL_TO_LOAD)\n",
    "    plot_filter_weights(nets, MODEL_TO_LOAD,style_layers, conv1_size=9, conv2_size=5, save_file=False)\n",
    "\n",
    "    if 'conv1_Weights_x_h_kernal' in nets.keys():\n",
    "        style_layers = [['conv1_Weights_x_h_kernal','conv1_bias']] #,['conv2_Weights','conv2_bias']]\n",
    "        plot_filter_weights(nets, MODEL_TO_LOAD,style_layers, conv1_size=9, conv2_size=5, save_file=False)\n",
    "\n",
    "    \n",
    "    \n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"{0:.2f}\".format(1.02345))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.colors as colors\n",
    "\n",
    "class MidpointNormalize(colors.Normalize):\n",
    "    def __init__(self, vmin=None, vmax=None, midpoint=None, clip=False):\n",
    "        self.midpoint = midpoint\n",
    "        colors.Normalize.__init__(self, vmin, vmax, clip)\n",
    "\n",
    "    def __call__(self, value, clip=None):\n",
    "        # I'm ignoring masked values and all kinds of edge cases to make a\n",
    "        # simple example...\n",
    "        x, y = [self.vmin, self.midpoint, self.vmax], [0, 0.5, 1]\n",
    "        return np.ma.masked_array(np.interp(value, x, y))\n",
    "\n",
    "def plot_filter_maps(nets,feed_dict,coch_batch,style_layers, conv1_size=9, conv2_size=5, save_file=False):\n",
    "    ## Takes in the style_layers and plots the filters (and the biases) for all of the filters of the layer. \n",
    "    ## Inputs: \n",
    "    ##      checkpoint_to_load = path to the checkpoint for the tensorflow model (as a string)\n",
    "    ##      style_layers = list of the layers of the network to plot\n",
    "    ##      conv1_size = the size of the first layer filters (used for making the network)\n",
    "    ##      conv2_size = the size of the second layer filters (used for making the network)\n",
    "    ##      save_file = False if the plots shouldn't be saved, a string to the base file name if they should be saved. \n",
    "    ## Returns:\n",
    "    ##      weights = dictionary with the filter weights for each layer as an array\n",
    "    ##      biases = dictionary with the filter biases for each layer\n",
    "    im = [23,23]\n",
    "    print(\"original cochleagram\")\n",
    "    fig, ax = plt.subplots(figsize=(18, 10))\n",
    "    #np.reshape(cochSet[index], (171,2000))\n",
    "    cax = ax.matshow(np.reshape(coch_batch[im[0]][0:COCHLEAGRAM_LENGTH], (171,int(COCHLEAGRAM_LENGTH/171))), origin='lower', cmap='inferno')\n",
    "    divider = make_axes_locatable(ax)\n",
    "    cax2 = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "    fig.colorbar(cax,cax=cax2)\n",
    "    ax.set_title(\"coch_image_{0}\".format(im[0]), y=1.2)\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(18, 10))\n",
    "    #np.reshape(cochSet[index], (171,2000))\n",
    "    cax = ax.matshow(np.reshape(coch_batch[im[0]][0:COCHLEAGRAM_LENGTH], (171,int(COCHLEAGRAM_LENGTH/171)))[:,0:171], origin='lower', cmap='inferno')\n",
    "    divider = make_axes_locatable(ax)\n",
    "    cax2 = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "    fig.colorbar(cax,cax=cax2)\n",
    "    ax.set_title(\"coch_image_{0}\".format(im[0]))\n",
    "    plt.show()\n",
    "    \n",
    "    weights = {}\n",
    "    for layer in range(len(style_layers)):\n",
    "        weights[layer] = sess.run(nets[style_layers[layer]],feed_dict=feed_dict)\n",
    "        print(weights[layer].shape)\n",
    "        \n",
    "        num_filters = weights[layer].shape[-1]\n",
    "        shape_filters = weights[layer].shape[1]\n",
    "        row_filters = weights\n",
    "        num_columns = 12\n",
    "        num_rows = np.ceil(num_filters/num_columns)\n",
    "        plt.figure(figsize=(60,5*num_rows))\n",
    "        for i in range(num_filters):\n",
    "            plt.subplot(num_rows,num_columns,i+1)\n",
    "            norm = MidpointNormalize(midpoint=0)\n",
    "            #plt.matshow(weights[layer][im,0:shape_filters,0:shape_filters,i], origin='lower', cmap='inferno') #weights[layer][im,0:3,0:3,i]\n",
    "            plt.matshow(weights[layer][im[layer],0:shape_filters,0:shape_filters,i], norm=norm, cmap=plt.cm.RdBu_r, fignum=False,\n",
    "                        vmin=weights[layer][im[layer],0:shape_filters,0:shape_filters,i].min()*2, vmax=weights[layer][im[layer],0:shape_filters,0:shape_filters,i].max()*2, interpolation='none', origin=\"lower\")\n",
    "            \n",
    "            M = weights[layer][im[layer],0:shape_filters,0:shape_filters,i].max()\n",
    "            m = weights[layer][im[layer],0:shape_filters,0:shape_filters,i].min()\n",
    "            \n",
    "           # plt.matshow(np.reshape(weights[layer][im,:,:,i],(171,int(COCHLEAGRAM_LENGTH/171)) )[:,0:171], norm=norm, cmap=plt.cm.RdBu_r, fignum=False,\n",
    "           #             vmin=weights[layer][im,0:shape_filters,0:shape_filters,i].min()*2, vmax=weights[layer][im,0:shape_filters,0:shape_filters,i].max()*2, interpolation='none', origin=\"lower\")\n",
    "            \n",
    "            \n",
    "            plt.title(\"filter {0}, Max {1}, Min {2}\".format(i,M,m))\n",
    "        plt.suptitle(\"Feature Maps for layer \" + str(layer), fontsize=24)\n",
    "        plt.show()\n",
    "        if save_file:\n",
    "            plt.savefig(save_file + layer + '_weights' + '.png')\n",
    "            plt.close()\n",
    "\n",
    "    return weights\n",
    "    \n",
    "style_layers = ['conv1','conv2']\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess,MODEL_TO_LOAD)\n",
    "    feed_dict={nets['input_to_net']:coch_batch,nets['actual_labels']:label_batch,nets['label_indeces']:indeces_list,nets['keep_prob']:1}\n",
    "    plot_filter_maps(nets,feed_dict, coch_batch,style_layers, conv1_size=9, conv2_size=5, save_file=False)\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#print individual filters and filtermaps\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess,MODEL_TO_LOAD)\n",
    "    conv1array,conv1weights= sess.run([nets['conv2'],nets['conv2_Weights']],feed_dict={nets['input_to_net']:coch_batch,nets['actual_labels']:label_batch,nets['label_indeces']:indeces_list,nets['keep_prob']:1})\n",
    "\n",
    "    im = 23\n",
    "    \n",
    "    for ch in range(0,96):#)96):\n",
    "        print(\"Cochleagram {0}, channel_{1}\".format(im,ch))\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(1, 1))\n",
    "        #print(conv1weights)\n",
    "        cax = ax.matshow(conv1weights[:,:,0,ch], origin='lower', cmap='Greys')\n",
    "        divider = make_axes_locatable(ax)\n",
    "        cax2 = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "        fig.colorbar(cax,cax2)\n",
    "        ax.set_title(\"cov1_weight_{0}_ch_{1}\".format(im,ch))\n",
    "        #print(conv1array[im,:,:,ch])\n",
    "        plt.show()\n",
    "\n",
    "        print(\"original coch\")\n",
    "        fig, ax = plt.subplots(figsize=(18, 10))\n",
    "        #np.reshape(cochSet[index], (171,2000))\n",
    "        cax = ax.matshow(np.reshape(coch_batch[im][0:COCHLEAGRAM_LENGTH], (171,int(COCHLEAGRAM_LENGTH/171))), origin='lower', cmap='inferno')\n",
    "        divider = make_axes_locatable(ax)\n",
    "        cax2 = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "        fig.colorbar(cax,cax=cax2)\n",
    "        ax.set_title(\"coch_image_{0}_ch_{1}\".format(im,ch))\n",
    "        plt.show()\n",
    "\n",
    "        print(\"feature_map\")\n",
    "        fig, ax = plt.subplots(figsize=(18, 10))\n",
    "        cax = ax.matshow(conv1array[im,:,:,ch], origin='lower', cmap='inferno')\n",
    "        divider = make_axes_locatable(ax)\n",
    "        cax2 = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "        fig.colorbar(cax,cax=cax2)\n",
    "        ax.set_title(\"cov1_image_{0}_ch_{1}\".format(im,ch))\n",
    "        #print(conv1array[im,:,:,ch])\n",
    "        plt.show()\n",
    "\n",
    "        print(\"histogram\")\n",
    "        fig, ax = plt.subplots(figsize=(9, 5))\n",
    "        n, bins, patches = ax.hist(conv1array[im,:,:,ch].flatten(), 50, normed=1, facecolor='green', alpha=0.75)\n",
    "        bincenters = 0.5*(bins[1:]+bins[:-1])\n",
    "        # add a 'best fit' line for the normal PDF\n",
    "        l = ax.plot(bincenters, bincenters, 'r--', linewidth=1)\n",
    "        ax.set_xlabel('Counts')\n",
    "        ax.set_ylabel('Values')\n",
    "        ax.grid(True)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#print the example sounds and their predictions\n",
    "\n",
    "from csv import reader\n",
    "import csv\n",
    "#plot predictions and the actual values\n",
    "def genLabelDictionary(path):\n",
    "    f = open(path)\n",
    "    dic = {}\n",
    "    f.readline()    \n",
    "    for line in reader(f):\n",
    "        base = line[1]\n",
    "        dic[base] = line[0]\n",
    "        dic[line[0]] = line[2]\n",
    "    \n",
    "    return dic   \n",
    "\n",
    "def get_label_list(dic, l):\n",
    "    string = \"\"\n",
    "    for i in l:\n",
    "        if str(i) in dic:\n",
    "            string = string + \"[{0}],\".format(dic[str(i)])\n",
    "        else:\n",
    "            return string\n",
    "    return string\n",
    "\n",
    "def get_label_arr(dic, l):\n",
    "    string = []\n",
    "    for i in l:\n",
    "        if str(i) in dic:\n",
    "            string.append(\"[{0}]\".format(dic[str(i)]))\n",
    "        else:\n",
    "            return string\n",
    "    return string\n",
    "\n",
    "def wavPlayer(filepath):\n",
    "    \"\"\" will display html 5 player for compatible browser\n",
    "\n",
    "    Parameters :\n",
    "    ------------\n",
    "    filepath : relative filepath with respect to the notebook directory ( where the .ipynb are not cwd)\n",
    "               of the file to play\n",
    "\n",
    "    The browser need to know how to play wav through html5.\n",
    "\n",
    "    there is no autoplay to prevent file playing when the browser opens\n",
    "    \"\"\"\n",
    "\n",
    "    src = \"\"\"\n",
    "    <head>\n",
    "    <meta http-equiv=\"Content-Type\" content=\"text/html; charset=utf-8\">\n",
    "    <title>Simple Test</title>\n",
    "    </head>\n",
    "\n",
    "    <body>\n",
    "    <audio controls=\"controls\" style=\"width:600px\" >\n",
    "      <source src=\"files/%s\" type=\"audio/wav\" />\n",
    "      Your browser does not support the audio element.\n",
    "    </audio>\n",
    "    </body>\n",
    "    \"\"\"%(filepath)\n",
    "    display(HTML(src))\n",
    "\n",
    "indeces_dict = genLabelDictionary(\"/home/ribeirop/mindhiveaudiofolder/class_labels_indices.csv\")\n",
    "#with sv.managed_session() as sess:\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess,MODEL_TO_LOAD)\n",
    "    numcorrect, predictions, pred_values = sess.run([nets['numCorrect'],nets['indeces'],nets['predicted_labels']],feed_dict={nets['input_to_net']:coch_batch,nets['actual_labels']:label_batch,nets['label_indeces']:indeces_list,nets['keep_prob']:1})    \n",
    "    print(\"Accuracy: \",numcorrect/total_count)\n",
    "    for i in range(0,len(label_batch)):\n",
    "        print(\"Sample {0}\".format(i))\n",
    "        print(test_indeces[i])\n",
    "        wavfile.write(\"TESTSOUNDS/test{0}.wav\".format(i),16000,wav_batch[i])\n",
    "        wavPlayer(\"TESTSOUNDS/test{0}.wav\".format(i))\n",
    "        print(\"Actual: {0}\".format(indeces_list[i]))\n",
    "        print(\"Predicted: {0}\".format(predictions[i]))\n",
    "        print()\n",
    "        print(\"Actual: {0}\".format(get_label_list(indeces_dict,indeces_list[i])))\n",
    "        predlabels = get_label_list(indeces_dict,predictions[i])\n",
    "        print(\"Predicted: {0}\".format(predlabels))\n",
    "        \n",
    "        \n",
    "        normed = pred_values[i]#/ pred_values[i].sum()\n",
    "        mypreds = []\n",
    "        for j in predictions[i]:\n",
    "            mypreds.append(pred_values[i][j])\n",
    "            \n",
    "        fig, ax = plt.subplots()\n",
    "        rects1 = ax.bar(np.arange(0,15), mypreds, .35, color='b')\n",
    "        \n",
    "        plt.setp(ax, xticks=np.arange(0,15), xticklabels=get_label_arr(indeces_dict,predictions[i]))\n",
    "        plt.setp( ax.xaxis.get_majorticklabels(), rotation=80)\n",
    "        #ax.set_xticklabels(get_label_arr(indeces_dict,predictions[i]),rotation=45)\n",
    "        plt.show()\n",
    "        \n",
    "        print()\n",
    "        print()\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#print the example sounds and their predictions\n",
    "#for the 165 sample condition\n",
    "from csv import reader\n",
    "import csv\n",
    "#plot predictions and the actual values\n",
    "def genLabelDictionary(path):\n",
    "    f = open(path)\n",
    "    dic = {}\n",
    "    f.readline()    \n",
    "    for line in reader(f):\n",
    "        base = line[1]\n",
    "        dic[base] = line[0]\n",
    "        dic[line[0]] = line[2]\n",
    "    \n",
    "    return dic   \n",
    "\n",
    "def get_label_list(dic, l):\n",
    "    string = \"\"\n",
    "    for i in l:\n",
    "        if str(i) in dic:\n",
    "            string = string + \"[{0}],\".format(dic[str(i)])\n",
    "        else:\n",
    "            return string\n",
    "    return string\n",
    "\n",
    "def get_label_arr(dic, l):\n",
    "    string = []\n",
    "    for i in l:\n",
    "        if str(i) in dic:\n",
    "            string.append(\"[{0}]\".format(dic[str(i)]))\n",
    "        else:\n",
    "            return string\n",
    "    return string\n",
    "\n",
    "def get_label_string(dic, l):\n",
    "    string = \"\"\n",
    "    for i in l:\n",
    "        if str(i) in dic:\n",
    "            string = string + \"[{0}]\".format(dic[str(i)])\n",
    "        else:\n",
    "            return string\n",
    "    return string\n",
    "\n",
    "def wavPlayer(filepath):\n",
    "    \"\"\" will display html 5 player for compatible browser\n",
    "\n",
    "    Parameters :\n",
    "    ------------\n",
    "    filepath : relative filepath with respect to the notebook directory ( where the .ipynb are not cwd)\n",
    "               of the file to play\n",
    "\n",
    "    The browser need to know how to play wav through html5.\n",
    "\n",
    "    there is no autoplay to prevent file playing when the browser opens\n",
    "    \"\"\"\n",
    "\n",
    "    src = \"\"\"\n",
    "    <head>\n",
    "    <meta http-equiv=\"Content-Type\" content=\"text/html; charset=utf-8\">\n",
    "    <title>Simple Test</title>\n",
    "    </head>\n",
    "\n",
    "    <body>\n",
    "    <audio controls=\"controls\" style=\"width:600px\" >\n",
    "      <source src=\"files/%s\" type=\"audio/wav\" />\n",
    "      Your browser does not support the audio element.\n",
    "    </audio>\n",
    "    </body>\n",
    "    \"\"\"%(filepath)\n",
    "    display(HTML(src))\n",
    "\n",
    "Wavs165 = hdf5file=h5py.File(\"/home/ribeirop/OMFOLDER/AUDIOSET_EXPERIMENTS/165_STRIPED/165_natural_sounds_copied.hdf5\")\n",
    "Cochs165 = h5py.File(\"/home/ribeirop/OMFOLDER/AUDIOSET_EXPERIMENTS/165_STRIPED/165_natural_sounds_copied_Coch.hdf5\")\n",
    "metadata = np.load(\"165_STRIPED/165_natural_sounds_copied_metadata.npy\")\n",
    "outfile = open(\"copied_predictions.csv\",\"w\")\n",
    "outfile.write(\"Copied Tests\\n\")\n",
    "\n",
    "\n",
    "'''Wavs165 = hdf5file=h5py.File(\"/home/ribeirop/OMFOLDER/AUDIOSET_EXPERIMENTS/165_STRIPED/165_natural_sounds_padded.hdf5\")\n",
    "Cochs165 = h5py.File(\"/home/ribeirop/OMFOLDER/AUDIOSET_EXPERIMENTS/165_STRIPED/165_natural_sounds_padded_Coch.hdf5\")\n",
    "metadata = np.load(\"165_STRIPED/165_natural_sounds_padded_metadata.npy\")\n",
    "outfile = open(\"padded_predictions.csv\",\"w\")\n",
    "outfile.write(\"Padded Tests\\n\")'''\n",
    "\n",
    "\n",
    "outfile.write(\"Sound,Actual,Predicted\\n\")\n",
    "\n",
    "\n",
    "wavSet165 = Wavs165[\"/wav\"]\n",
    "cochSet165 = Cochs165[\"/coch\"]\n",
    "labelSet165 = Cochs165[\"/labels\"]    \n",
    "    \n",
    "indeces_dict = genLabelDictionary(\"/home/ribeirop/mindhiveaudiofolder/class_labels_indices.csv\")\n",
    "#with sv.managed_session() as sess:\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess,MODEL_TO_LOAD)\n",
    "    numcorrect = 0\n",
    "    numcorrect15 = 0\n",
    "    predictions = []\n",
    "    pred_values = []\n",
    "    batchsize = 55\n",
    "    total_count165 = 0\n",
    "    full_indeces_list165 = []\n",
    "    for i in range(0,int(165/batchsize)):\n",
    "        start = i * batchsize\n",
    "        end = start+batchsize\n",
    "        \n",
    "        indeces_list165 = []\n",
    "        for row in labelSet165[start:end]:\n",
    "            indeces= np.where(row==1)[0]\n",
    "            total_count165 = total_count165 + len(indeces)\n",
    "            indeces_list165.append(np.pad(indeces,[0,15-len(indeces)],mode = 'constant',constant_values=-1))\n",
    "            full_indeces_list165.append(np.pad(indeces,[0,15-len(indeces)],mode = 'constant',constant_values=-1))\n",
    "            \n",
    "        addme,top15addme, predictions_batch, pred_values_batch = sess.run([nets['numCorrect_top_pred'],nets['numCorrect'],nets['indeces'],nets['predicted_labels']],feed_dict={nets['input_to_net']:cochSet165[start:end],nets['actual_labels']:labelSet165[start:end],nets['label_indeces']:indeces_list165,nets['keep_prob']:1})    \n",
    "\n",
    "        numcorrect = numcorrect + addme\n",
    "        numcorrect15 = numcorrect15 + top15addme\n",
    "        for b in predictions_batch:\n",
    "            predictions.append(b)\n",
    "        for b in pred_values_batch:\n",
    "            pred_values.append(b)\n",
    "            \n",
    "            \n",
    "\n",
    "    print(\"Accuracy: \",numcorrect15/total_count165)\n",
    "    print(\"Accuracy: \",numcorrect/165)\n",
    "    for i in range(0,165):\n",
    "        print(\"Sample {0}\".format(i))\n",
    "        wavfile.write(\"TESTSOUNDS/test{0}.wav\".format(i),16000,wavSet165[i])\n",
    "        wavPlayer(\"TESTSOUNDS/test{0}.wav\".format(i))\n",
    "        print(\"Actual: {0}\".format(full_indeces_list165[i]))\n",
    "        print(\"Predicted: {0}\".format(predictions[i]))\n",
    "        print()\n",
    "        print(\"Actual: {0}\".format(get_label_list(indeces_dict,full_indeces_list165[i])))\n",
    "        predlabels = get_label_list(indeces_dict,predictions[i])\n",
    "        print(\"Predicted: {0}\".format(predlabels))\n",
    "        \n",
    "        print(\"###\")\n",
    "        names = metadata[i][0]\n",
    "        labels =  get_label_string(indeces_dict,full_indeces_list165[i][:5])\n",
    "        preds = get_label_string(indeces_dict,predictions[i][:5])\n",
    "        print(\"{0},{1},{2}\".format(names,labels,preds))\n",
    "        outfile.write(\"\\\"{0}\\\",\\\"{1}\\\",\\\"{2}\\\"\\n\".format(names,labels,preds))\n",
    "        print(\"###\")\n",
    "        \n",
    "        normed = pred_values[i]#/ pred_values[i].sum()\n",
    "        mypreds = []\n",
    "        for j in predictions[i]:\n",
    "            mypreds.append(pred_values[i][j])\n",
    "            \n",
    "        '''fig, ax = plt.subplots()\n",
    "        rects1 = ax.bar(np.arange(0,15), mypreds, .35, color='b')\n",
    "        \n",
    "        plt.setp(ax, xticks=np.arange(0,15), xticklabels=get_label_arr(indeces_dict,predictions[i]))\n",
    "        plt.setp( ax.xaxis.get_majorticklabels(), rotation=80)\n",
    "        #ax.set_xticklabels(get_label_arr(indeces_dict,predictions[i]),rotation=45)\n",
    "        plt.show()'''\n",
    "        \n",
    "        print()\n",
    "        print()\n",
    "        \n",
    "outfile.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Generate corolation matrix p1:\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import sys\n",
    "import h5py\n",
    "import random\n",
    "import math\n",
    "from math import sqrt\n",
    "import argparse\n",
    "from csv import reader\n",
    "import csv\n",
    "\n",
    "from IPython.core.display import HTML, display\n",
    "import scipy.signal as signal\n",
    "from scipy.io import wavfile\n",
    "\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.mlab as mlab\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "def genLabelDictionary(path):\n",
    "    f = open(path)\n",
    "    dic = {}\n",
    "    f.readline()    \n",
    "    for line in reader(f):\n",
    "        base = line[1]\n",
    "        dic[base] = line[0]\n",
    "        dic[line[0]] = line[2]\n",
    "    \n",
    "    return dic\n",
    "\n",
    "def plotMatrix(grid,title,englishLabels, xlabel = \"\",ylabel=\"\"): \n",
    "    fig, ax = plt.subplots(figsize=(100, 100))\n",
    "    ax.set_title(title,fontsize = 100)\n",
    "    plt.setp(ax, xticks=np.arange(0,527), xticklabels=englishLabels, yticks=np.arange(0,527), yticklabels=englishLabels)\n",
    "    plt.setp( ax.xaxis.get_majorticklabels(), rotation=90 )\n",
    "    plt.setp( ax.yaxis.get_majorticklabels(), rotation=0 )\n",
    "\n",
    "    #plt.figure(figsize = (100,100))\n",
    "    mat = ax.imshow(grid,interpolation='nearest',cmap='inferno')\n",
    "    divider = make_axes_locatable(ax)\n",
    "    cax2 = divider.append_axes(\"right\", size=\"2%\", pad=0.05)\n",
    "    #plt.xticks(np.arange(527), englishLabels,rotation='vertical')\n",
    "    #plt.yticks(np.arange(527), englishLabels)\n",
    "    cbar = fig.colorbar(mat,cax2)\n",
    "    #plt.grid(color='w', linestyle='-', linewidth=1,which='minor')\n",
    "    cbar.ax.tick_params(labelsize=100) \n",
    "    ax.set_xlabel( xlabel,fontsize = 100)\n",
    "    ax.set_ylabel( ylabel,fontsize = 100)\n",
    "    \n",
    "indeces_dict = genLabelDictionary(\"/home/ribeirop/mindhiveaudiofolder/class_labels_indices.csv\")\n",
    "englishLabels = [None]*527\n",
    "for i in range(0,527):\n",
    "    englishLabels[i] = indeces_dict[str(i)]\n",
    "\n",
    "Cochs = h5py.File(\"/home/ribeirop/OMFOLDER/audiosetDL/eval_stripped/eval_segments_Coch.hdf5\")\n",
    "\n",
    "labelSet = Cochs[\"/labels\"]\n",
    "Correlation_Matrix = np.corrcoef(labelSet,rowvar=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plotMatrix(Correlation_Matrix,\"Real Labels Correlation Matrix\",englishLabels,\"\",\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "newset = []\n",
    "for row in range(len(Correlation_Matrix)):\n",
    "    #np.pad(labelSet[row][0:row],[0,15-len(indeces)],mode = 'constant',constant_values=0))\n",
    "    newset.append(np.pad(Correlation_Matrix[row][0:row],[0,527-row],mode = 'constant',constant_values=0))\n",
    "\n",
    "\n",
    "plotMatrix(newset,\"Real Labels Correlation Matrix\",englishLabels,\"Actual\",\"Predicted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EVALUATE ON EVAL SET\n",
    "\n",
    "#Correlation Matrix of top 15 Predictions\n",
    "#Error comes because it just never predicts a couple of labels in the top 15\n",
    "#P1: Training\n",
    "testsize = 20000#Cochs.attrs.get(\"size\")\n",
    "batchsize = 100\n",
    "\n",
    "index_list = []\n",
    "predictions_list = []\n",
    "correct_indeces = []\n",
    "\n",
    "calculator = AveragePrecisionCalculator(15)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess,MODEL_TO_LOAD)\n",
    "    \n",
    "    #run on testSEt\n",
    "    startindex = 0\n",
    "    endindex = startindex+batchsize\n",
    "    total_count = 0\n",
    "    correct = 0\n",
    "    correct_train = 0\n",
    "    while(endindex <= testsize):\n",
    "        print(startindex)\n",
    "        trainBatchLabels = labelSet[startindex:endindex]\n",
    "        indeces_list_batch = []\n",
    "        for row in trainBatchLabels:\n",
    "            indeces= np.where(row==1)[0]\n",
    "            total_count = total_count + len(indeces)\n",
    "            indeces_list_batch.append(np.pad(indeces,[0,15-len(indeces)],mode = 'constant',constant_values=-1))\n",
    "            correct_indeces.append(np.pad(indeces,[0,15-len(indeces)],mode = 'constant',constant_values=-1))\n",
    "            \n",
    "        addme, indeces,predictions = sess.run([nets['numCorrect'],nets['indeces'],nets['predicted_labels']],feed_dict={nets['input_to_net']:cochSet[startindex:endindex],nets['actual_labels']:trainBatchLabels,nets['label_indeces']:indeces_list_batch,nets['keep_prob']:1})\n",
    "    \n",
    "        #print(predictions.flatten())\n",
    "        #print(trainBatchLabels.flatten())\n",
    "        #calculator.accumulate(predictions.flatten(), trainBatchLabels.flatten())\n",
    "    \n",
    "        for i in range(len(predictions)):\n",
    "            #predictions[i][137] = min(predictions[i])\n",
    "            #predictions[i][0] = min(predictions[i])\n",
    "            normed = predictions[i] / abs(predictions[i]).max()\n",
    "            sort = normed.argsort()[::-1]        \n",
    "            calculator.accumulate(normed[sort][0:15],trainBatchLabels[0][sort][0:15],total_count)\n",
    "    \n",
    "        correct = correct + addme\n",
    "    \n",
    "        for l in indeces:\n",
    "            index_list.append(l)\n",
    "            \n",
    "        for p in predictions:\n",
    "            predictions_list.append(p)\n",
    "        \n",
    "        startindex = endindex\n",
    "        endindex = startindex+batchsize\n",
    "        \n",
    "        \n",
    "print(\"Accuracy: \", correct / total_count)\n",
    "print(\"GAP: \", calculator.peek_ap_at_n() )\n",
    "oneHots = np.zeros([len(indeces),527])\n",
    "for row in range(len(indeces)):\n",
    "    for index in indeces[row]:\n",
    "        oneHots[row][index] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#EVALUATE ON EVAL SET\n",
    "\n",
    "#Correlation Matrix of top 15 Predictions\n",
    "#Error comes because it just never predicts a couple of labels in the top 15\n",
    "#P1: Training\n",
    "testsize = 20000#Cochs.attrs.get(\"size\")\n",
    "batchsize = 100\n",
    "\n",
    "index_list = []\n",
    "predictions_list = []\n",
    "correct_indeces = []\n",
    "\n",
    "calculator = AveragePrecisionCalculator()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess,MODEL_TO_LOAD)\n",
    "    \n",
    "    #run on testSEt\n",
    "    startindex = 0\n",
    "    endindex = startindex+batchsize\n",
    "\n",
    "    correct = 0\n",
    "    correct_train = 0\n",
    "    sumofGAP = 0\n",
    "    \n",
    "    predicted_list = []\n",
    "    actual_list = []\n",
    "    for j in range(0,20):\n",
    "        trainBatchLabels = [labelSet[j]]\n",
    "        indeces_list_batch = []\n",
    "        total_count = 0\n",
    "        for row in trainBatchLabels:\n",
    "            indeces= np.where(row==1)[0]\n",
    "            total_count = total_count + len(indeces)\n",
    "            indeces_list_batch.append(np.pad(indeces,[0,15-len(indeces)],mode = 'constant',constant_values=-1))\n",
    "            correct_indeces.append(np.pad(indeces,[0,15-len(indeces)],mode = 'constant',constant_values=-1))\n",
    "            \n",
    "        addme, indeces,predictions = sess.run([nets['numCorrect'],nets['indeces'],nets['predicted_labels']],feed_dict={nets['input_to_net']:[cochSet[j]],nets['actual_labels']:trainBatchLabels,nets['label_indeces']:indeces_list_batch,nets['keep_prob']:1})\n",
    "    \n",
    "        #print(predictions.flatten())\n",
    "        #print(trainBatchLabels.flatten())\n",
    "        #calculator.accumulate(predictions.flatten(), trainBatchLabels.flatten())\n",
    "    \n",
    "\n",
    "        normed = predictions[0] / abs(predictions[0]).max()\n",
    "        sort = normed.argsort()[::-1]\n",
    "        \n",
    "        calculator.accumulate(normed[sort][0:15],trainBatchLabels[0][sort][0:15],total_count)\n",
    "        \n",
    "        predicted_list.append(normed)\n",
    "        actual_list.append(trainBatchLabels[0])\n",
    "        #print(normed)\n",
    "        #print(trainBatchLabels[0])\n",
    "        thisgap = AveragePrecisionCalculator.ap_at_n(normed,trainBatchLabels[0],15) #AveragePrecisionCalculator.ap(normed,trainBatchLabels[0])\n",
    "        sumofGAP = sumofGAP + thisgap\n",
    "        print(\"######\")\n",
    "        print(\"{0} GAP: {1}\".format(j,thisgap))\n",
    "        print(\"{0} myGAP: {1}\".format(j,calc_ap(predicted_list,actual_list)))\n",
    "        print(\"Accumulated GAP: \", calculator.peek_ap_at_n() )\n",
    "        print(\"{0} myGAP accumulated: {1}\".format(j,calc_ap([normed],[trainBatchLabels[0]])))\n",
    "        print(\"numcorrect: {0}, total {1}, acc {2}\".format(addme,total_count,addme/total_count))\n",
    "        print(\"Actual: \",indeces_list_batch[0])\n",
    "        print(\"Predicted: \", indeces)\n",
    "        \n",
    "        \n",
    "print(\"###\")        \n",
    "print(\"Accumulated GAP: \", calculator.peek_ap_at_n() )\n",
    "print(\"Ave GAP: \", sumofGAP/20)\n",
    "print(\"myGAP: \", calc_ap(predicted_list,actual_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Calulate AP\n",
    "#print(predicted_list)\n",
    "#print(actual_list)\n",
    "\n",
    "#from sklearn.metrics import average_precision_score\n",
    "def calc_ap(predicted,actual, n = 15):\n",
    "    predicted = np.array(predicted)\n",
    "    actual=np.array(actual)\n",
    "    \n",
    "    recall = 1/len(np.where(np.array(actual).flatten()>0)[0])\n",
    "    predicted = np.array(predicted)\n",
    "    actual = np.array(actual)\n",
    "    \n",
    "    for i in range(0,len(predicted)):\n",
    "        sort = predicted[i].argsort()[::-1]\n",
    "        predicted[i] = np.array(predicted[i])[sort]\n",
    "        actual[i] = np.array(actual[i])[sort]\n",
    "    \n",
    "    #print(predicted[:,0:15])\n",
    "    #print(actual[:,0:15])\n",
    "    \n",
    "    predicted = predicted[:,0:n].flatten()\n",
    "    actual = actual[:,0:n].flatten()\n",
    "    \n",
    "    #print(\"YEEE \", average_precision_score(actual,predicted))\n",
    "    \n",
    "    sort = predicted.argsort()[::-1]\n",
    "    predicted = predicted[sort]\n",
    "    actual = actual[sort]\n",
    "    \n",
    "    #print(predicted)\n",
    "    #print(actual)\n",
    "    \n",
    "    GAP = 0\n",
    "    \n",
    "    #print(actual)\n",
    "    #print(recall)\n",
    "    numcorrect = 0\n",
    "    for i in range(len(predicted)):\n",
    "        numcorrect = numcorrect + actual[i]\n",
    "        precision = numcorrect/(i+1)\n",
    "        GAP = GAP + precision*recall * actual[i]\n",
    "        \n",
    "    #print(\"GAP is {0}\".format(GAP))\n",
    "    return GAP\n",
    "    \n",
    "\n",
    "print(\"GAP \",calc_ap([[.6,.4,.2],[.9,.8,.7]],[[1,1,0],[1,0,1]] )  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(predictions)\n",
    "print(indeces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "grid = np.corrcoef(oneHots,rowvar=False)\n",
    "plotMatrix(grid ,\"Predicted top-15 Labels Correlation Matrix\",englishLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "grid = np.corrcoef(predictions_list,rowvar=False)\n",
    "plotMatrix(grid ,\"Predicted full Labels Correlation Matrix\",englishLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Plot True Positives\n",
    "\n",
    "Total_label_counts = np.zeros([527]) #total number of times each label occured.\n",
    "Total_correct_counts = np.zeros([527]) #total number of times you got that label correct\n",
    "\n",
    "for sample in range(len(correct_indeces)):\n",
    "    for label in correct_indeces[sample]:\n",
    "        if not label == -1:\n",
    "            Total_label_counts[label] += 1\n",
    "            if(label in index_list[sample] ):\n",
    "                Total_correct_counts[label] += 1\n",
    "\n",
    "percentages = np.divide(Total_correct_counts,Total_label_counts)\n",
    "\n",
    "#print(percentages)\n",
    "\n",
    "sorting = percentages.argsort()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(100, 50))\n",
    "rects1 = ax.bar(np.arange(0,527),percentages[sorting], .35, color='b')\n",
    "\n",
    "plt.setp(ax, xticks=np.arange(0,527), xticklabels=np.array(englishLabels)[sorting])\n",
    "plt.setp( ax.xaxis.get_majorticklabels(), rotation=80)\n",
    "#ax.set_xticklabels(get_label_arr(indeces_dict,predictions[i]),rotation=45)\n",
    "plt.title(\"Accuracy per Label\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Plot Confidence Matrix\n",
    "#predictions_list\n",
    "Confidence_matrix = np.zeros([527,527])\n",
    "predictions_list = np.array(predictions_list)\n",
    "\n",
    "for sample in range(len(correct_indeces)):\n",
    "    if(sample%1000 == 0):\n",
    "        print(sample)\n",
    "    normed = predictions_list[sample]/abs(predictions_list[sample]).max()\n",
    "    #normed = predictions_list[sample]/predictions_list[sample].sum()\n",
    "    \n",
    "    #normed = np.linalg.norm(predictions_list,np.inf)\n",
    "    for label in correct_indeces[sample]:\n",
    "        if not label == -1:\n",
    "            Confidence_matrix[label] += normed\n",
    "\n",
    "for row in range(len(Confidence_matrix)):\n",
    "    Confidence_matrix[row] = np.divide(Confidence_matrix[row],Total_label_counts[row])\n",
    "        \n",
    "\n",
    "\n",
    "plotMatrix(Confidence_matrix,\"Predicted full Labels Confidence_matrix\",englishLabels,\"predicted\",\"actual\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Plot Confidence Matrix\n",
    "#softmax\n",
    "#predictions_list\n",
    "\n",
    "def softmax(x):\n",
    "    \"\"\"\n",
    "    Compute softmax values for each sets of scores in x.\n",
    "    \n",
    "    Rows are scores for each class. \n",
    "    Columns are predictions (samples).\n",
    "    \"\"\"\n",
    "    scoreMatExp = np.exp(np.asarray(x))\n",
    "    return scoreMatExp / scoreMatExp.sum(0)\n",
    "\n",
    "Confidence_matrix = np.zeros([527,527])\n",
    "predictions_list = np.array(predictions_list)\n",
    "\n",
    "for sample in range(len(correct_indeces)):\n",
    "    if(sample%1000 == 0):\n",
    "        print(sample)\n",
    "    #normed = predictions_list[sample]/abs(predictions_list[sample]).max()\n",
    "    normed = softmax(predictions_list[sample])\n",
    "    #normed = predictions_list[sample]/predictions_list[sample].sum()\n",
    "    \n",
    "    #normed = np.linalg.norm(predictions_list,np.inf)\n",
    "    for label in correct_indeces[sample]:\n",
    "        if not label == -1:\n",
    "            Confidence_matrix[label] += normed\n",
    "            \n",
    "for row in range(len(Confidence_matrix)):\n",
    "    Confidence_matrix[row] = np.divide(Confidence_matrix[row],Total_label_counts[row])\n",
    "        \n",
    "Confidence_matrix = np.log(Confidence_matrix)\n",
    "\n",
    "plotMatrix(Confidence_matrix,\"Predicted full Labels Confidence_matrix\",englishLabels,\"predicted\",\"actual\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Plot Confidence Matrix\n",
    "#cut off at N number of labels\n",
    "#predictions_list\n",
    "Confidence_matrix = np.zeros([527,527])\n",
    "predictions_list = np.array(predictions_list)\n",
    "count = 0\n",
    "for sample in range(len(correct_indeces)):\n",
    "    if(sample%1000 == 0):\n",
    "        print(sample)\n",
    "    normed = predictions_list[sample]/abs(predictions_list[sample]).max()\n",
    "    #normed = np.linalg.norm(predictions_list,np.inf)\n",
    "    if correct_indeces[sample][2] == -1:\n",
    "        count += 1\n",
    "        for label in correct_indeces[sample]:\n",
    "            if not label == -1:\n",
    "                Confidence_matrix[label] += normed\n",
    "\n",
    "for row in range(len(Confidence_matrix)):\n",
    "    Confidence_matrix[row] = np.divide(Confidence_matrix[row],Total_label_counts[row])\n",
    "        \n",
    "print(\"count: \", count)\n",
    "Confidence_matrix[Confidence_matrix == 0] = 'nan'\n",
    "plotMatrix(Confidence_matrix,\"Confidence_matrix\",englishLabels,\"predicted\",\"actual\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import sys\n",
    "import h5py\n",
    "import random\n",
    "import math\n",
    "from math import sqrt\n",
    "import argparse\n",
    "\n",
    "from IPython.core.display import HTML, display\n",
    "import scipy.signal as signal\n",
    "from scipy.io import wavfile\n",
    "\n",
    "\n",
    "\n",
    "def wavPlayer(filepath):\n",
    "    \"\"\" will display html 5 player for compatible browser\n",
    "\n",
    "    Parameters :\n",
    "    ------------\n",
    "    filepath : relative filepath with respect to the notebook directory ( where the .ipynb are not cwd)\n",
    "               of the file to play\n",
    "\n",
    "    The browser need to know how to play wav through html5.\n",
    "\n",
    "    there is no autoplay to prevent file playing when the browser opens\n",
    "    \"\"\"\n",
    "\n",
    "    src = \"\"\"\n",
    "    <head>\n",
    "    <meta http-equiv=\"Content-Type\" content=\"text/html; charset=utf-8\">\n",
    "    <title>Simple Test</title>\n",
    "    </head>\n",
    "\n",
    "    <body>\n",
    "    <audio controls=\"controls\" style=\"width:600px\" >\n",
    "      <source src=\"files/%s\" type=\"audio/wav\" />\n",
    "      Your browser does not support the audio element.\n",
    "    </audio>\n",
    "    </body>\n",
    "    \"\"\"%(filepath)\n",
    "    display(HTML(src))\n",
    "    \n",
    "wavPlayer(\"/../../../../mindhive/mcdermott/shared/Sounds/165_natural_sounds/stim97_crickets.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from PedrosNetworkFunctionsALPHA import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "p = np.array([random.random() for _ in range(10)])\n",
    "a = np.array([random.choice([0, 1]) for _ in range(10)])\n",
    "print(a)\n",
    "print(p)\n",
    "ap = AveragePrecisionCalculator.ap(p, a)\n",
    "\n",
    "print(ap)\n",
    "print()\n",
    "\n",
    "print(AveragePrecisionCalculator.ap([1,0,0,0,0],[0,1,0,0,0]))\n",
    "print(AveragePrecisionCalculator.ap([0,1,0,0,0],[0,1,0,0,0]))\n",
    "print(AveragePrecisionCalculator.ap([0,0,1,0,0],[0,1,0,0,0]))\n",
    "print(AveragePrecisionCalculator.ap([0,0,0,1,0],[0,1,0,0,0]))\n",
    "print(AveragePrecisionCalculator.ap([0,0,0,0,1],[0,1,0,0,0]))\n",
    "\n",
    "print(AveragePrecisionCalculator.ap([.9,.8,.7,.6,.4,.2],[1,0,1,1,1,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "calculator = AveragePrecisionCalculator(150)\n",
    "\n",
    "calculator.accumulate(np.array([.6,.4,.2]),np.array([1,1,0]))\n",
    "calculator.accumulate( np.flip(np.array([.9,.8,.7]),0) , np.flip(np.array([1,0,1]),0))\n",
    "\n",
    "\n",
    "print(calculator.peek_ap_at_n())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "calculator = AveragePrecisionCalculator(150)\n",
    "\n",
    "calculator.accumulate(np.array([.6,.4,.2]),np.array([True,True,False]))\n",
    "calculator.accumulate( np.flip(np.array([.9,.8,.7]),0) , np.flip(np.array([True,False,True]),0))\n",
    "\n",
    "\n",
    "print(calculator.peek_ap_at_n())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "calculator = AveragePrecisionCalculator(150)\n",
    "\n",
    "calculator.accumulate(np.array([-.7,-.8,-.9]),np.array([True,True,False]))\n",
    "calculator.accumulate( np.flip(np.array([-.4,-.5,-.6]),0) , np.flip(np.array([True,False,True]),0))\n",
    "\n",
    "\n",
    "print(calculator.peek_ap_at_n())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p1 = np.array([random.random() for _ in range(5)])\n",
    "a1 = np.array([random.choice([0, 1]) for _ in range(5)])\n",
    "p2 = np.array([random.random() for _ in range(5)])\n",
    "a2 = np.array([random.choice([0, 1]) for _ in range(5)])\n",
    "# interpolated average precision at 10 using 1000 break points\n",
    "calculator = AveragePrecisionCalculator(10)\n",
    "calculator.accumulate(p1, a1)\n",
    "calculator.accumulate(p2, a2)\n",
    "ap3 = calculator.peek_ap_at_n()\n",
    "print(ap3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
