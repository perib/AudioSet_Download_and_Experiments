{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time  33.43720078468323\n",
      "final [ 3.84075444  3.93302376  3.79997796 ...,  0.99986121  1.05200649\n",
      "  1.1569437 ]\n",
      "done averaging\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "#RESTART AND CLEAR BECAUSE THE TENSORFLOW GRAPH PERSISTS\n",
    "'''\n",
    "audiosetDL\n",
    "\n",
    "Pedro Ribeiro\n",
    "Josh McDermotts Lab\n",
    "MSRP BIO 2017\n",
    "\n",
    "documentation: https://github.mit.edu/ribeirop/AudioSetDL/blob/master/README.md\n",
    "\n",
    "'''\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from csv import reader\n",
    "import csv\n",
    "from scipy.io import wavfile\n",
    "import scipy\n",
    "import h5py\n",
    "import glob\n",
    "import scipy.signal as signal\n",
    "import argparse\n",
    "import h5py\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import resource\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from IPython.core.display import HTML, display\n",
    "from scipy.io import wavfile\n",
    "\n",
    "from tensorflow.python.client import timeline\n",
    "\n",
    "sys.path.insert(0, './HELPER_PROGRAMS/tfcochleagram')\n",
    "import tfcochleagram\n",
    "#for debugging and sanity checks\n",
    "def wavPlayer(filepath):\n",
    "    \"\"\" will display html 5 player for compatible browser\n",
    "\n",
    "    Parameters :\n",
    "    ------------\n",
    "    filepath : relative filepath with respect to the notebook directory ( where the .ipynb are not cwd)\n",
    "               of the file to play\n",
    "\n",
    "    The browser need to know how to play wav through html5.\n",
    "\n",
    "    there is no autoplay to prevent file playing when the browser opens\n",
    "    \"\"\"\n",
    "\n",
    "    src = \"\"\"\n",
    "    <head>\n",
    "    <meta http-equiv=\"Content-Type\" content=\"text/html; charset=utf-8\">\n",
    "    <title>Simple Test</title>\n",
    "    </head>\n",
    "\n",
    "    <body>\n",
    "    <audio controls=\"controls\" style=\"width:600px\" >\n",
    "      <source src=\"files/%s\" type=\"audio/wav\" />\n",
    "      Your browser does not support the audio element.\n",
    "    </audio>\n",
    "    </body>\n",
    "    \"\"\"%(filepath)\n",
    "    display(HTML(src))\n",
    "    \n",
    "#creates a dictionary for easy access from labels to indeces\n",
    "def genLabelDictionary(path):\n",
    "    f = open(path)\n",
    "    dic = {}\n",
    "    f.readline()    \n",
    "    for line in reader(f):\n",
    "        base = line[1]\n",
    "        dic[base] = line[0]\n",
    "        dic[line[0]] = line[2]\n",
    "    \n",
    "    return dic  \n",
    "\n",
    "def MEAN(outputfile = \"/om/user/ribeirop/audiosetDL/balanced_stripped/\",wavHDF5file = \"/om/user/ribeirop/audiosetDL/balanced_stripped/balanced_train_segments.hdf5\"):\n",
    "    #create the files for the databases  \n",
    "    basename = os.path.splitext(os.path.basename(wavHDF5file))[0]\n",
    "    \n",
    "    Storage = h5py.File(\"{0}{1}_Coch.hdf5\".format(outputfile,basename),\"r\")\n",
    "\n",
    "    cochSet = Storage[\"/coch\"]\n",
    "        \n",
    "    cochlabelSet = Storage[\"/labels\"]\n",
    "    \n",
    "    totalNumber = Storage.attrs.get(\"size\")\n",
    "    \n",
    "    \n",
    "    sums = np.zeros(cochSet[0].shape, dtype=np.float64)\n",
    "    batchSize = 10000\n",
    "    current_start = 0\n",
    "    while(current_start + batchSize <= totalNumber):\n",
    "        end = current_start + batchSize\n",
    "        av = np.mean(cochSet[current_start:end],axis = 0, dtype=np.float64)  \n",
    "        sums = np.add(sums , np.multiply(av , np.divide((end-current_start),(totalNumber)),dtype=np.float64))\n",
    "        current_start = current_start + batchSize\n",
    "    \n",
    "    if(current_start < totalNumber):\n",
    "        end = current_start + (totalNumber-current_start)\n",
    "        av = np.mean(cochSet[current_start:end],axis = 0, dtype=np.float64)  \n",
    "        sums = np.add(sums , np.multiply(av , np.divide((end-current_start),(totalNumber)),dtype=np.float64))\n",
    "        current_start = current_start + batchSize\n",
    "    \n",
    "    \n",
    "    \n",
    "    print(\"final\", sums)\n",
    "    np.save(\"{0}{1}_average.npy\".format(outputfile,basename),sums)\n",
    "    \n",
    "    Storage.close()\n",
    "    print(\"done averaging\")\n",
    "    \n",
    "\n",
    "# -o', '--outputPath' : path to where you want the final HDF5 file to be stored. \n",
    "# '-w', '--wavHDF5file' : path to the HDF5 file containing the wavs created by Wav_into_HDF5\n",
    "def main(outputfile = \"/om/user/ribeirop/audiosetDL/\",wavHDF5file = \"/om/user/ribeirop/audiosetDL/thousand_tests.hdf5\",SR=16000,N=40,SAMPLE_FACTOR=4,LOW_LIM=20,HIGH_LIM=8000,compression='sqrt',ENV_SR=200):\n",
    "    #create the files for the databases  \n",
    "    basename = os.path.splitext(os.path.basename(wavHDF5file))[0]\n",
    "    \n",
    "    #342000 is how long the flatted thing is\n",
    "    #np.reshape(arr, (171,2000)) to get the original cochleagram\n",
    "    \n",
    "    wavHDF5 = h5py.File(wavHDF5file,'r')\n",
    "    \n",
    "    wavSet = wavHDF5[\"/wav\"]\n",
    "    labelSet = wavHDF5[\"/labels\"]\n",
    "    \n",
    "    numberofFiles = wavHDF5.attrs.get(\"size\") \n",
    "    \n",
    "    # TODO: make sure its documented that this runs two cochleagrams at a time -- its possible that if longer ones were used it could only do 1. Alternatively, it could be make more generic to determine the max batch size that fits on the GPU.\n",
    "    audio = wavSet[0:2]\n",
    "    end_coch_size = [N*SAMPLE_FACTOR+11,ENV_SR*audio.shape[-1]/SR]\n",
    "    \n",
    "    Storage = h5py.File(\"{0}{1}_Coch.hdf5\".format(outputfile,basename))\n",
    "    if(not \"/coch\" in Storage):\n",
    "        cochSet = Storage.create_dataset(\"coch\",(numberofFiles,end_coch_size[0]*end_coch_size[1]),dtype=np.float32)\n",
    "    else:\n",
    "        cochSet = Storage[\"/coch\"]\n",
    "        \n",
    "    if(not \"/labels\" in Storage):\n",
    "        # TODO: change 527 so that it looks at labels and gets the max number -- don't hard code it in. \n",
    "        cochlabelSet = Storage.create_dataset(\"labels\",(numberofFiles,527),dtype=bool)\n",
    "    else:\n",
    "        cochlabelSet = Storage[\"/labels\"]\n",
    "    \n",
    "    Storage.attrs.create(\"size\",numberofFiles)\n",
    "    \n",
    "    with tf.Graph().as_default():\n",
    "        #makes the graph\n",
    "        if len(audio.shape) == 1: # we need to make sure the input node has a first dimension that corresponds to the batch size\n",
    "            audio = np.expand_dims(audio,0) \n",
    "        nets = {}\n",
    "        nets['input_signal'] = tf.Variable(audio, dtype=tf.float32)\n",
    "        nets = tfcochleagram.cochleagram_graph(nets, audio.shape[-1], SR,LOW_LIM=LOW_LIM, HIGH_LIM=HIGH_LIM,N=N,SAMPLE_FACTOR=SAMPLE_FACTOR, compression=compression,ENV_SR=ENV_SR) # use the default values\n",
    "        nets['cochleagram_reshaped']=tf.reshape(nets['cochleagram'],[2, -1])\n",
    "        #run_metadata = tf.RunMetadata()\n",
    "        \n",
    "        with tf.Session() as sess:\n",
    "               #LOOP HERE\n",
    "            start = time.time()\n",
    "            for i in range(0,numberofFiles-1,2):\n",
    "             #   print(resource.getrusage(resource.RUSAGE_SELF).ru_maxrss)\n",
    "                audio = wavSet[i:i+2]\n",
    "                #cochleagram = nets['cochleagram'].eval(feed_dict = {nets['input_signal']:audio})\n",
    "\n",
    "                cochSet[i:i+2] = nets['cochleagram_reshaped'].eval(feed_dict = {nets['input_signal']:audio})\n",
    "               \n",
    "                cochlabelSet[i:i+2] = labelSet[i:i+2]\n",
    "            \n",
    "            if(numberofFiles%2 ==1):\n",
    "                audio = wavSet[numberofFiles-2:numberofFiles]\n",
    "                cochSet[numberofFiles-2:numberofFiles] = nets['cochleagram_reshaped'].eval(feed_dict = {nets['input_signal']:audio})\n",
    "                cochlabelSet[numberofFiles-2:numberofFiles] = labelSet[numberofFiles-2:numberofFiles]\n",
    "\n",
    "            end = time.time()\n",
    "            \n",
    "            print(\"Time \",end-start)\n",
    "            \n",
    "            #trace = timeline.Timeline(step_stats=run_metadata.step_stats)\n",
    "            #trace_file = open('timeline.ctf.json', 'w')\n",
    "            #trace_file.write(trace.generate_chrome_trace_format())\n",
    "\n",
    "\n",
    "    Storage.close()\n",
    "    \n",
    "    MEAN(outputfile,wavHDF5file) #calculates and saves the mean\n",
    "    print(\"Done.\")\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    debug = True\n",
    "    if debug:\n",
    "        main()\n",
    "    else:        \n",
    "        parser = argparse.ArgumentParser()\n",
    "        parser.add_argument('-o', '--outputfile') #where to put the hdf5 file\n",
    "        parser.add_argument('-w', '--wavHDF5file') #where the csv is\n",
    "\n",
    "        args = vars(parser.parse_args())\n",
    "\n",
    "        outputfile = args[\"outputfile\"]\n",
    "        wavHDF5file= args[\"wavHDF5file\"]\n",
    "        \n",
    "        main(outputfile = outputfile,wavHDF5file=wavHDF5file)\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#SANITY CHECKS\n",
    "import h5py\n",
    "import scipy.signal as signal\n",
    "from scipy.io import wavfile\n",
    "import scipy\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, './HELPER_PROGRAMS/tfcochleagram')\n",
    "\n",
    "def genLabelDictionary(path):\n",
    "    f = open(path)\n",
    "    dic = {}\n",
    "    f.readline()    \n",
    "    for line in reader(f):\n",
    "        base = line[1]\n",
    "        dic[base] = line[0]\n",
    "        dic[line[0]] = line[2]\n",
    "    \n",
    "    return dic   \n",
    "\n",
    "def wavPlayer(filepath):\n",
    "    \"\"\" will display html 5 player for compatible browser\n",
    "\n",
    "    Parameters :\n",
    "    ------------\n",
    "    filepath : relative filepath with respect to the notebook directory ( where the .ipynb are not cwd)\n",
    "               of the file to play\n",
    "\n",
    "    The browser need to know how to play wav through html5.\n",
    "\n",
    "    there is no autoplay to prevent file playing when the browser opens\n",
    "    \"\"\"\n",
    "\n",
    "    src = \"\"\"\n",
    "    <head>\n",
    "    <meta http-equiv=\"Content-Type\" content=\"text/html; charset=utf-8\">\n",
    "    <title>Simple Test</title>\n",
    "    </head>\n",
    "\n",
    "    <body>\n",
    "    <audio controls=\"controls\" style=\"width:600px\" >\n",
    "      <source src=\"files/%s\" type=\"audio/wav\" />\n",
    "      Your browser does not support the audio element.\n",
    "    </audio>\n",
    "    </body>\n",
    "    \"\"\"%(filepath)\n",
    "    display(HTML(src))\n",
    "\n",
    "    \n",
    "hdf5file=h5py.File(\"/home/ribeirop/OMFOLDER/audiosetDL/thousand_tests.hdf5\")\n",
    "Cochs = h5py.File(\"/home/ribeirop/OMFOLDER/audiosetDL/thousand_tests_Coch.hdf5\")\n",
    "\n",
    "wavSet = hdf5file[\"/wav\"]\n",
    "cochSet = Cochs[\"/coch\"]\n",
    "labelSet = Cochs[\"/labels\"]\n",
    "\n",
    "index = 10\n",
    "\n",
    "audio = wavSet[index]\n",
    "unraveled = np.reshape(cochSet[index], (171,200))\n",
    "labels = labelSet[index]\n",
    "\n",
    "wavfile.write(\"test.wav\",16000,audio)\n",
    "wavPlayer(\"test.wav\")\n",
    "\n",
    "indeces_dict = genLabelDictionary(\"class_labels_indices.csv\")\n",
    "indeces = np.where(labels == 1)[0]\n",
    "for i in indeces:\n",
    "    print(indeces_dict[str(i)])\n",
    "    \n",
    "\n",
    "plt.matshow(unraveled, origin='lower', cmap='inferno')\n",
    "plt.colorbar()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final [ 3.82251241  3.914079    3.78556621 ...,  1.00853041  1.05024515\n",
      "  1.15711963]\n",
      "done averaging\n"
     ]
    }
   ],
   "source": [
    "#calculate mean coch\n",
    "import os\n",
    "import h5py\n",
    "import resource\n",
    "import numpy as np\n",
    "def MEAN(outputfile = \"/om/user/ribeirop/audiosetDL/balanced_stripped/\",wavHDF5file = \"/om/user/ribeirop/audiosetDL/balanced_stripped/balanced_train_segments.hdf5\"):\n",
    "    #create the files for the databases  \n",
    "    basename = os.path.splitext(os.path.basename(wavHDF5file))[0]\n",
    "    \n",
    "    Storage = h5py.File(\"{0}{1}_Coch.hdf5\".format(outputfile,basename),\"r\")\n",
    "\n",
    "    cochSet = Storage[\"/coch\"]\n",
    "        \n",
    "    cochlabelSet = Storage[\"/labels\"]\n",
    "    \n",
    "    totalNumber = cochSet.shape[0]\n",
    "    \n",
    "    \n",
    "    sums = np.zeros(cochSet[0].shape, dtype=np.float64)\n",
    "    batchSize = 10000\n",
    "    current_start = 0\n",
    "    while(current_start + batchSize <= totalNumber):\n",
    "        end = current_start + batchSize\n",
    "        av = np.mean(cochSet[current_start:end],axis = 0, dtype=np.float64)  \n",
    "        sums = np.add(sums , np.multiply(av , np.divide((end-current_start),(totalNumber)),dtype=np.float64))\n",
    "        current_start = current_start + batchSize\n",
    "    \n",
    "    if(current_start < totalNumber):\n",
    "        end = current_start + (totalNumber-current_start)\n",
    "        av = np.mean(cochSet[current_start:end],axis = 0, dtype=np.float64)  \n",
    "        sums = np.add(sums , np.multiply(av , np.divide((end-current_start),(totalNumber)),dtype=np.float64))\n",
    "        current_start = current_start + batchSize\n",
    "    \n",
    "    \n",
    "    \n",
    "    print(\"final\", sums)\n",
    "    np.save(\"{0}{1}_average.npy\".format(outputfile,basename),sums)\n",
    "    \n",
    "    Storage.close()\n",
    "    print(\"done averaging\")\n",
    "    \n",
    "MEAN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "summing = np.array([0],np.float32)\n",
    "prev = np.array([0],np.float32)\n",
    "for i in range(0,500):\n",
    "    summing[0] = summing[0] + random.randint(50,100) +.00001\n",
    "    if(summing[0] == prev[0]):\n",
    "        print(\"fuck\")\n",
    "        print(i)\n",
    "        print(summing[0])\n",
    "        print(prev[0])\n",
    "        break\n",
    "        \n",
    "    prev[0] = summing[0]\n",
    "    \n",
    "print(summing)\n",
    "old = np.array([summing[0]],np.float32)\n",
    "summing[0] = summing[0] + .876572\n",
    "print(summing[0] == old[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = np.zeros((2, 2000000), dtype=np.float32)\n",
    "x = 51\n",
    "y = 60.1\n",
    "a[0, :] = x\n",
    "a[1, :] = y\n",
    "print(np.mean(a))\n",
    "print(np.mean(a, dtype=np.float64))\n",
    "\n",
    "print((x+y)/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.divide(1,2,dtype=np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
